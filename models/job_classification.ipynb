{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13d4da90-35a2-4e72-ae17-dd6ff9b68aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des librairies\n",
    "import torch\n",
    "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48373af9-f603-4d67-b0bb-2ad0ac9f92ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Director of Program Management%2C Information ...</td>\n",
       "      <td>Information technology (IT) directors of progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Disaster Recovery Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Disaster Recovery Specialist%2C IT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Document Control Supervisor</td>\n",
       "      <td>A document control supervisor are responsible ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Documentation Manager</td>\n",
       "      <td>Documentation managers are responsible for man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   job  \\\n",
       "196  Director of Program Management%2C Information ...   \n",
       "197                          Disaster Recovery Analyst   \n",
       "198                 Disaster Recovery Specialist%2C IT   \n",
       "199                        Document Control Supervisor   \n",
       "200                              Documentation Manager   \n",
       "\n",
       "                                           description  \n",
       "196  Information technology (IT) directors of progr...  \n",
       "197                                                NaN  \n",
       "198                                                NaN  \n",
       "199  A document control supervisor are responsible ...  \n",
       "200  Documentation managers are responsible for man...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 2)\n"
     ]
    }
   ],
   "source": [
    "# import des donn√©es\n",
    "df = pd.read_csv(\"../data/silver/job_description.csv\")\n",
    "display(df.tail())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3454016d-a670-4546-a099-92c295390e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a295cf82-4ed0-4046-85a8-a9314634ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list = df['job'].tolist()\n",
    "description_list = df['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01de11b2-208f-43f5-9cc8-36de1d849726",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_jobs = list(set(job_list))\n",
    "job_to_id = {job: idx for idx, job in enumerate(unique_jobs)}\n",
    "id_to_job = {idx: job for job, idx in job_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d6855d-8d3a-42de-b016-755f5a012d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6379fc28-01ca-4198-940a-66a8789aeb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8afc6203-fb25-4478-95be-94713f38b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model we gonna train, base uncased BERT\n",
    "# check text classification models here: https://huggingface.co/models?filter=text-classification\n",
    "model_name = \"bert-base-uncased\"\n",
    "# max sequence length for each document/sentence sample\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a8d2af1-6579-45f1-bbfc-0acf037f268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f96089d3-35e3-4c9a-b847-d9d3bb39d6c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize the dataset, truncate when passed `max_length`, \n",
    "# and pad with 0's when less than `max_length`\n",
    "train_encodings = tokenizer(description_list, truncation=True, padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae1329f2-5f68-4c9b-ad85-baa7b558bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobDescriptionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, job_to_id):\n",
    "        self.encodings = encodings\n",
    "        self.labels = [job_to_id[job] for job in labels]\n",
    "        self.job_to_id = job_to_id\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04864458-56bc-4b8f-80c0-ae61e2cb720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = JobDescriptionDataset(train_encodings, job_list, job_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b160d1e1-3d0a-4df7-a47d-862811c67a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the model and pass to CUDA\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(unique_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c993a920-f1ed-421a-bd96-68845a3ce161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ebdb635-4698-4cd4-be0c-ee5d19768ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./model_results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=400,               # log & save weights each logging_steps\n",
    "    save_steps=400,\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "604ec2a7-a1f3-4743-87f8-e27b9ad3113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    # eval_dataset=valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b9fd5-f5d9-4869-8ad2-ea56896ba5d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e658a3d-eb8c-46fe-a8f3-3e906bf4cdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b327af0-e4d7-4370-9041-8580a1ff0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # perform inference to our model\n",
    "    outputs = model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return target_names[probs.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a792f9-aa07-42ef-b9cc-d3459795bcca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
