{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15261594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des librairies\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# srapping\n",
    "import requests \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "# clean data\n",
    "import ast\n",
    "import dateparser\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#export data\n",
    "import time\n",
    "import os\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57179fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\selmane.kenzari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\selmane.kenzari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3edcb285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonctions\n",
    "def scrapping():\n",
    "    job_offers = []\n",
    "    page = 0\n",
    "    # Select URL\n",
    "    url = f'https://candidat.pole-emploi.fr/offres/recherche?emission=31&motsCles=data&offresPartenaires=true&range=0-19&rayon=10&tri=0'\n",
    "    while True:\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        \n",
    "#         # Check if the URL is not recognized or does not exist\n",
    "#         if response.status_code != 200:\n",
    "#             break\n",
    "            \n",
    "        html_content = response.text\n",
    "            \n",
    "        with open ('page.html', 'w', encoding='utf-8') as file:\n",
    "            file.write(html_content)\n",
    "\n",
    "        with open('page.html', 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        soup = bs(html_content, 'html.parser')\n",
    "\n",
    "        job_elements = soup.find_all('div', class_='media-body')\n",
    "        \n",
    "        for job_element in job_elements:\n",
    "            # Extract the data-intitule-offre value from the job summary element\n",
    "            \n",
    "            if job_element.find('h2') and job_element.find('h2')['data-intitule-offre']:\n",
    "                data_intitule_offre = job_element.find('h2')['data-intitule-offre']\n",
    "            \n",
    "                # Construct the detail page URL using the data-intitule-offre value\n",
    "                detail_page_url = f'https://candidat.pole-emploi.fr/offres/recherche/detail/{data_intitule_offre}'\n",
    "\n",
    "                # Scrape job details from the detail page\n",
    "                detail_page_response = requests.get(detail_page_url)\n",
    "                detail_page_content = detail_page_response.text\n",
    "\n",
    "                with open ('page.html', 'w', encoding='utf-8') as file:\n",
    "                    file.write(detail_page_content)\n",
    "\n",
    "                with open('page.html', 'r', encoding='utf-8') as file:\n",
    "                    detail_page_content = file.read()\n",
    "\n",
    "                detail_page_soup = bs(detail_page_content, 'html.parser')\n",
    "                \n",
    "                # Liste des variables à extraire\n",
    "                variables = {\n",
    "                    'jobs': ('span', 'title'),\n",
    "                    'description': ('div', 'description col-sm-8 col-md-7'),\n",
    "                    'loc': ('span', 'name'),\n",
    "                    'datePosted': ('span', 'datePosted'),\n",
    "                    'workhours': ('dd', 'workHours'),\n",
    "                    'salary': ('span', 'baseSalary'),\n",
    "                    'contract_type': ('dl', 'icon-group'),\n",
    "                    'experience': ('span', 'experienceRequirements'),\n",
    "                    'qualifications': ('span', 'qualifications'),\n",
    "                    'industry': ('span', 'industry'),\n",
    "                    'company': ('h3', 't4 title'),\n",
    "                    'size': ('div', 'media-body'),\n",
    "                    'company_description': ('p', 'italic'),\n",
    "                    'diploma': ('span', 'educationRequirements')\n",
    "                }\n",
    "\n",
    "                # Boucle pour extraire les variables\n",
    "                for var, (tag, class_) in variables.items():\n",
    "                    try:\n",
    "                        if var in ['salary', 'contract_type']:\n",
    "                            if var == 'salary':\n",
    "                                try:\n",
    "                                    salary_raw = detail_page_soup.find(tag, itemprop=class_)\n",
    "                                    min_value = salary_raw.find('span', itemprop='minValue').get('content').strip()\n",
    "                                    max_value = salary_raw.find('span', itemprop='maxValue').get('content').strip()\n",
    "                                    globals()[var] = f\"{min_value} - {max_value}\"\n",
    "                                except AttributeError:\n",
    "                                    salary_match = re.search(r'content=\"([\\d.]+)\" itemprop=\"value\"', str(salary_raw))\n",
    "                                    globals()[var] = salary_match.group(1) if salary_match else math.nan\n",
    "                                    \n",
    "                            elif var == 'contract_type':\n",
    "                                contract_type_raw = detail_page_soup.find(tag, class_=class_).find('dd')\n",
    "                                globals()[var] = str(contract_type_raw.contents[0]).strip()\n",
    "                                \n",
    "                        else:\n",
    "                            globals()[var] = detail_page_soup.find(tag, itemprop=class_).text.replace('\\n', '').strip()\n",
    "                    except AttributeError:\n",
    "                        # En cas d'erreur\n",
    "                        globals()[var] = math.nan\n",
    "\n",
    "\n",
    "                # Extraction des autres variables spécifiques\n",
    "                try:\n",
    "                    skills_raw = detail_page_soup.find_all('span', itemprop='skills')\n",
    "                    skills = [skill.text.strip() for skill in skills_raw]\n",
    "                except AttributeError:\n",
    "                    # En cas d'erreur\n",
    "                    skills_raw = ''\n",
    "                    skills = math.nan\n",
    "                    \n",
    "                try:\n",
    "                    company = detail_page_soup.find('h3', class_='t4 title').text.strip()\n",
    "                except AttributeError:\n",
    "                    company = math.nan\n",
    "                    \n",
    "                try:\n",
    "                    size = detail_page_soup.find('div', class_='media-body').find('p').text.strip()\n",
    "                except AttributeError:\n",
    "                    size = math.nan\n",
    "                    \n",
    "                try:                    \n",
    "                    company_description = detail_page_soup.find('p', class_='italic').text.replace('\\n', '').strip()\n",
    "                except AttributeError:\n",
    "                    company_description = math.nan\n",
    "                \n",
    "                try: \n",
    "                    description = detail_page_soup.find('div', class_='description col-sm-8 col-md-7').text.strip()\n",
    "                except AttributeError:\n",
    "                    description = math.nan\n",
    "                    \n",
    "\n",
    "                # Create a dictionary for the scraped data\n",
    "                data = {\n",
    "                    'jobs': jobs,\n",
    "                    'description': description,\n",
    "                    'loc': loc,\n",
    "                    'datePosted': datePosted,\n",
    "                    'workhours': workhours,\n",
    "                    'salary': salary,\n",
    "                    'contract_type': contract_type,\n",
    "                    'experience': experience,\n",
    "                    'diploma': diploma,\n",
    "                    'skills': skills,\n",
    "                    'qualifications': qualifications,\n",
    "                    'industry': industry,\n",
    "                    'company': company,\n",
    "                    'size': size,\n",
    "                    'company_description': company_description\n",
    "                }\n",
    "\n",
    "                job_offers.append(data)\n",
    "            \n",
    "            else : \n",
    "                print(f'fin de la page {page}!')\n",
    "\n",
    "        # Extract the href of the next page button\n",
    "        next_page_link = soup.find('div', id='zoneAfficherPlus').find('a')\n",
    "        if next_page_link:\n",
    "            href_main_page = next_page_link['href']\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # Construct the URL for the next page\n",
    "        next_page_url = f'https://candidat.pole-emploi.fr{href_main_page}'\n",
    "        \n",
    "        # Delay before navigating to the next page\n",
    "        time.sleep(60)\n",
    "        \n",
    "        # Update the URL to the next page\n",
    "        url = next_page_url\n",
    "        page += 1\n",
    "\n",
    "    # Transform the dictionary into a dataframe\n",
    "    df = pd.DataFrame(job_offers)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4beac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin de la page 0!\n",
      "fin de la page 1!\n",
      "fin de la page 2!\n",
      "fin de la page 3!\n",
      "fin de la page 4!\n",
      "fin de la page 5!\n",
      "fin de la page 6!\n",
      "fin de la page 7!\n",
      "fin de la page 8!\n",
      "fin de la page 9!\n",
      "fin de la page 10!\n",
      "fin de la page 11!\n",
      "fin de la page 12!\n",
      "fin de la page 13!\n",
      "fin de la page 14!\n",
      "fin de la page 15!\n",
      "fin de la page 16!\n",
      "fin de la page 17!\n",
      "fin de la page 18!\n",
      "fin de la page 19!\n",
      "fin de la page 20!\n",
      "fin de la page 21!\n",
      "fin de la page 22!\n",
      "fin de la page 23!\n",
      "fin de la page 24!\n",
      "fin de la page 25!\n",
      "fin de la page 26!\n",
      "fin de la page 27!\n",
      "fin de la page 28!\n",
      "fin de la page 29!\n",
      "fin de la page 30!\n",
      "fin de la page 31!\n",
      "fin de la page 32!\n",
      "fin de la page 33!\n",
      "fin de la page 34!\n",
      "fin de la page 35!\n",
      "fin de la page 36!\n",
      "fin de la page 37!\n",
      "fin de la page 38!\n",
      "fin de la page 39!\n",
      "fin de la page 40!\n",
      "fin de la page 41!\n",
      "fin de la page 42!\n",
      "fin de la page 43!\n",
      "fin de la page 44!\n",
      "fin de la page 45!\n",
      "fin de la page 46!\n",
      "fin de la page 47!\n",
      "fin de la page 48!\n",
      "fin de la page 49!\n"
     ]
    }
   ],
   "source": [
    "df = scrapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ed7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobs</th>\n",
       "      <th>description</th>\n",
       "      <th>loc</th>\n",
       "      <th>datePosted</th>\n",
       "      <th>workhours</th>\n",
       "      <th>salary</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>experience</th>\n",
       "      <th>diploma</th>\n",
       "      <th>skills</th>\n",
       "      <th>qualifications</th>\n",
       "      <th>industry</th>\n",
       "      <th>company</th>\n",
       "      <th>size</th>\n",
       "      <th>company_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANALYSTE APPLICATIF DATA FINANCE RH (H/F)</td>\n",
       "      <td>Dans le cadre d'un important projet avec un gr...</td>\n",
       "      <td>92 - ISSY LES MOULINEAUX</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>50000.0 - 60000.0</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>2 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Adapter les outils de traitement statistique ...</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>Conseil en systèmes et logiciels informatiques</td>\n",
       "      <td>INFORMATIS T.S.</td>\n",
       "      <td>6 à 9 salariés</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ingénieur DATA (H/F)</td>\n",
       "      <td>Nous recherchons : un Ingénieur DATA H/F.\\n\\nP...</td>\n",
       "      <td>92 - PUTEAUX</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>2 ans</td>\n",
       "      <td>Bac+3, Bac+4 ou équivalents</td>\n",
       "      <td>[Application web, Concevoir une application we...</td>\n",
       "      <td>Agent de maîtrise</td>\n",
       "      <td>Conseil pour les affaires et autres conseils d...</td>\n",
       "      <td>IL CONSULTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Integrity Analyst  (H/F)</td>\n",
       "      <td>ADECCO Lyon Pharma recherche un Data Integrity...</td>\n",
       "      <td>69 - ST PRIEST</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>2311.0</td>\n",
       "      <td>Mission intérimaire - 12 Mois</td>\n",
       "      <td>Débutant accepté</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Adapter les outils de traitement statistique ...</td>\n",
       "      <td>Employé qualifié</td>\n",
       "      <td>Activités des agences de travail temporaire</td>\n",
       "      <td>ADECCO Onsite</td>\n",
       "      <td>0 salarié (n'ayant pas d'effectif au 31/12 mai...</td>\n",
       "      <td>Premier réseau d'agences d'emploi en France, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technicien Data (h/f)</td>\n",
       "      <td>Adecco PONTARLIER, recherche pour l'un de ses ...</td>\n",
       "      <td>25 - PONTARLIER</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>Débutant accepté</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Concevoir et gérer un projet, Concevoir un lo...</td>\n",
       "      <td>Employé qualifié</td>\n",
       "      <td>Activités des agences de travail temporaire</td>\n",
       "      <td>ADECCO</td>\n",
       "      <td>6 à 9 salariés</td>\n",
       "      <td>Premier réseau d'agences d'emploi en France, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer        (H/F)</td>\n",
       "      <td>Selon vos expériences, votre mission sera de :...</td>\n",
       "      <td>33 - BORDEAUX</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>38H30 Travail en journée</td>\n",
       "      <td>30000.0 - 50000.0</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>3 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>Conseil en systèmes et logiciels informatiques</td>\n",
       "      <td>THELIO</td>\n",
       "      <td>20 à 49 salariés</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        jobs  \\\n",
       "0  ANALYSTE APPLICATIF DATA FINANCE RH (H/F)   \n",
       "1                       Ingénieur DATA (H/F)   \n",
       "2              Data Integrity Analyst  (H/F)   \n",
       "3                      Technicien Data (h/f)   \n",
       "4                 Data Engineer        (H/F)   \n",
       "\n",
       "                                         description  \\\n",
       "0  Dans le cadre d'un important projet avec un gr...   \n",
       "1  Nous recherchons : un Ingénieur DATA H/F.\\n\\nP...   \n",
       "2  ADECCO Lyon Pharma recherche un Data Integrity...   \n",
       "3  Adecco PONTARLIER, recherche pour l'un de ses ...   \n",
       "4  Selon vos expériences, votre mission sera de :...   \n",
       "\n",
       "                        loc                 datePosted  \\\n",
       "0  92 - ISSY LES MOULINEAUX  Actualisé le 07 août 2023   \n",
       "1              92 - PUTEAUX  Actualisé le 07 août 2023   \n",
       "2            69 - ST PRIEST  Actualisé le 07 août 2023   \n",
       "3           25 - PONTARLIER  Actualisé le 07 août 2023   \n",
       "4             33 - BORDEAUX  Actualisé le 07 août 2023   \n",
       "\n",
       "                  workhours             salary                  contract_type  \\\n",
       "0    35H Travail en journée  50000.0 - 60000.0   Contrat à durée indéterminée   \n",
       "1    35H Travail en journée                NaN   Contrat à durée indéterminée   \n",
       "2    35H Travail en journée             2311.0  Mission intérimaire - 12 Mois   \n",
       "3    35H Travail en journée                NaN   Contrat à durée indéterminée   \n",
       "4  38H30 Travail en journée  30000.0 - 50000.0   Contrat à durée indéterminée   \n",
       "\n",
       "         experience                      diploma  \\\n",
       "0             2 ans                          NaN   \n",
       "1             2 ans  Bac+3, Bac+4 ou équivalents   \n",
       "2  Débutant accepté                          NaN   \n",
       "3  Débutant accepté                          NaN   \n",
       "4             3 ans                          NaN   \n",
       "\n",
       "                                              skills     qualifications  \\\n",
       "0  [Adapter les outils de traitement statistique ...              Cadre   \n",
       "1  [Application web, Concevoir une application we...  Agent de maîtrise   \n",
       "2  [Adapter les outils de traitement statistique ...   Employé qualifié   \n",
       "3  [Concevoir et gérer un projet, Concevoir un lo...   Employé qualifié   \n",
       "4                                                 []              Cadre   \n",
       "\n",
       "                                            industry          company  \\\n",
       "0     Conseil en systèmes et logiciels informatiques  INFORMATIS T.S.   \n",
       "1  Conseil pour les affaires et autres conseils d...    IL CONSULTING   \n",
       "2        Activités des agences de travail temporaire    ADECCO Onsite   \n",
       "3        Activités des agences de travail temporaire           ADECCO   \n",
       "4     Conseil en systèmes et logiciels informatiques           THELIO   \n",
       "\n",
       "                                                size  \\\n",
       "0                                     6 à 9 salariés   \n",
       "1                                                NaN   \n",
       "2  0 salarié (n'ayant pas d'effectif au 31/12 mai...   \n",
       "3                                     6 à 9 salariés   \n",
       "4                                   20 à 49 salariés   \n",
       "\n",
       "                                 company_description  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  Premier réseau d'agences d'emploi en France, A...  \n",
       "3  Premier réseau d'agences d'emploi en France, A...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f2f39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2859b",
   "metadata": {},
   "source": [
    "### Export df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da06fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_raw_data(df):\n",
    "    csv_file_path = f\"../data/bronze/raw_data.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfc2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_raw_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6735d",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c22c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [\"AWS S3\", \"Azure Blob Storage\", \"Google Cloud Storage\", \"Dropbox\", \"Box\", \"OneDrive\", \"Salesforce\", \"HubSpot\",\n",
    "               \"Slack\", \"Microsoft Teams\", \"Google Workspace\", \"Trello\", \"Jira\", \"Confluence\", \"GitHub\", \"GitLab\", \"Jenkins\",\n",
    "               \"CircleCI\", \"Travis CI\", \"Docker\", \"Kubernetes\", \"Apache Hadoop\", \"Apache Spark\", \"Apache Kafka\", \"Apache Storm\",\n",
    "               \"Elasticsearch\", \"Logstash\", \"Kibana\", \"Grafana\", \"Prometheus\", \"Nagios\", \"Splunk\", \"Tableau\", \"Power BI\",\n",
    "               \"QlikView\", \"Looker\", \"Dataiku\", \"Alteryx\", \"Talend\", \"Informatica\", \"Matillion\", \"Databricks\", \"Snowflake\",\n",
    "               \"Amazon Redshift\", \"Google BigQuery\", \"Microsoft Azure SQL Database\", \"Oracle Database\", \"MySQL\", \"PostgreSQL\",\n",
    "               \"MongoDB\", \"Couchbase\", \"Cassandra\", \"Neo4j\", \"Apache Airflow\", \"Luigi\", \"Celery\", \"Apache NiFi\", \n",
    "               \"Talend Data Integration\", \"Google Cloud Dataflow\", \"Apache Beam\", \"Apache Flink\", \n",
    "               \"Microsoft Azure Data Factory\", \"IBM InfoSphere DataStage\", \"Apache Samza\", \"Apache Flume\",\n",
    "               \"Apache Sqoop\", \"Microsoft Azure Databricks\", \"Teradata\", \"IBM Db2\", \"Apache Zeppelin\", \n",
    "               \"Jupyter Notebook\", \"Google Colab\", \"Anaconda\", \"TensorFlow\", \"PyTorch\", \"Keras\",\n",
    "               \"scikit-learn\", \"XGBoost\", \"LightGBM\", \"H2O.ai\", \"Apache Mahout\", \"Microsoft Azure Machine Learning\", \n",
    "               \"IBM Watson\", \"RapidMiner\", \"KNIME\", \"DataRobot\", \"Amazon SageMaker\", \"Google Cloud AI Platform\",\n",
    "               \"Domo\", \"IBM Cognos\", \"SAS\", \"Oracle Analytics Cloud\", \"Microsoft Power Automate\",\n",
    "               \"Apache NiFi Registry\", \"Apache Atlas\", \"Apache Metron\", \"Apache Knox\", \"Apache Ranger\",\n",
    "               \"Apache Superset\", \"Microsoft Power Apps\", \"Salesforce Einstein Analytics\",\n",
    "               \"Google Data Studio\", \"Pentaho\", \"Microsoft Azure Synapse Analytics\",\n",
    "               \"SAP Analytics Cloud\", \"MicroStrategy\", \"RStudio\", \"Apache Kylin\", \n",
    "               \"Apache HBase\", \"Apache Pig\", \"Apache Hive\", \"Apache Drill\",\n",
    "               \"Cloudera Data Platform\", \"Hortonworks Data Platform\", \"Qubole\", \"DataRobot\", \"DataRobot Insights\",\n",
    "               \"DataRobot MLOps\", \"DataRobot Paxata\", \"DataRobot AutoML\", \"DataRobot Time Series\", \"DataRobot AI Catalog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8826cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tools(df, liste):\n",
    "    tools_list = [tool.lower() for tool in liste]\n",
    "    \n",
    "    def find_tools(description):\n",
    "        # Convertir la description en minuscules\n",
    "        description = description.lower()\n",
    "\n",
    "        # Créer une liste pour stocker les outils trouvés\n",
    "        tools_found = []\n",
    "\n",
    "        # Chercher chaque outil dans la description\n",
    "        for tool in tools_list:\n",
    "            if tool in description:\n",
    "                tools_found.append(tool)\n",
    "        \n",
    "        # Si aucun outil n'a été trouvé, retourner NaN\n",
    "        if not tools_found:\n",
    "            return math.nan\n",
    "\n",
    "        return ', '.join(tools_found)  # Retourner la liste d'outils trouvés\n",
    "    \n",
    "    df['tools'] = df['description'].apply(find_tools)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb086d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_skills(df):\n",
    "    \n",
    "    def clean_skills(list_skills_str):\n",
    "        \n",
    "        # Convertir la chaîne en une liste\n",
    "        try:\n",
    "            list_skills = ast.literal_eval(list_skills_str)\n",
    "        except ValueError:\n",
    "            # Si la conversion échoue, retourner la valeur telle quelle\n",
    "            return list_skills_str\n",
    "        \n",
    "        # Assurez-vous que list_skills est une liste\n",
    "        if isinstance(list_skills, list):\n",
    "            clean_list = [skill.lower() for skill in list_skills]  # Convertir chaque compétence en minuscules\n",
    "        else:\n",
    "            # Si ce n'est pas une liste, retournez la valeur telle quelle\n",
    "            return list_skills_str\n",
    "            \n",
    "        return ', '.join(clean_list)\n",
    "    \n",
    "    df['skills'] = df['skills'].apply(clean_skills)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09074046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_tools(df, tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ef050e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_skills(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "043926dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobs</th>\n",
       "      <th>description</th>\n",
       "      <th>loc</th>\n",
       "      <th>datePosted</th>\n",
       "      <th>workhours</th>\n",
       "      <th>salary</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>experience</th>\n",
       "      <th>diploma</th>\n",
       "      <th>skills</th>\n",
       "      <th>qualifications</th>\n",
       "      <th>industry</th>\n",
       "      <th>company</th>\n",
       "      <th>size</th>\n",
       "      <th>company_description</th>\n",
       "      <th>tools</th>\n",
       "      <th>ID_dep</th>\n",
       "      <th>ville</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANALYSTE APPLICATIF DATA FINANCE RH (H/F)</td>\n",
       "      <td>Dans le cadre d'un important projet avec un gr...</td>\n",
       "      <td>92 - ISSY LES MOULINEAUX</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>50000.0 - 60000.0</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>2 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Adapter les outils de traitement statistique ...</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>Conseil en systèmes et logiciels informatiques</td>\n",
       "      <td>INFORMATIS T.S.</td>\n",
       "      <td>6 à 9 salariés</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>ISSY LES MOULINEAUX</td>\n",
       "      <td>2023/08/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ingénieur DATA (H/F)</td>\n",
       "      <td>Nous recherchons : un Ingénieur DATA H/F.\\n\\nP...</td>\n",
       "      <td>92 - PUTEAUX</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>2 ans</td>\n",
       "      <td>Bac+3, Bac+4 ou équivalents</td>\n",
       "      <td>[Application web, Concevoir une application we...</td>\n",
       "      <td>Agent de maîtrise</td>\n",
       "      <td>Conseil pour les affaires et autres conseils d...</td>\n",
       "      <td>IL CONSULTING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gitlab, kubernetes, mongodb</td>\n",
       "      <td>92</td>\n",
       "      <td>PUTEAUX</td>\n",
       "      <td>2023/08/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Integrity Analyst  (H/F)</td>\n",
       "      <td>ADECCO Lyon Pharma recherche un Data Integrity...</td>\n",
       "      <td>69 - ST PRIEST</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>2311.0</td>\n",
       "      <td>Mission intérimaire - 12 Mois</td>\n",
       "      <td>Débutant accepté</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Adapter les outils de traitement statistique ...</td>\n",
       "      <td>Employé qualifié</td>\n",
       "      <td>Activités des agences de travail temporaire</td>\n",
       "      <td>ADECCO Onsite</td>\n",
       "      <td>0 salarié (n'ayant pas d'effectif au 31/12 mai...</td>\n",
       "      <td>Premier réseau d'agences d'emploi en France, A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>ST PRIEST</td>\n",
       "      <td>2023/08/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technicien Data (h/f)</td>\n",
       "      <td>Adecco PONTARLIER, recherche pour l'un de ses ...</td>\n",
       "      <td>25 - PONTARLIER</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>Débutant accepté</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Concevoir et gérer un projet, Concevoir un lo...</td>\n",
       "      <td>Employé qualifié</td>\n",
       "      <td>Activités des agences de travail temporaire</td>\n",
       "      <td>ADECCO</td>\n",
       "      <td>6 à 9 salariés</td>\n",
       "      <td>Premier réseau d'agences d'emploi en France, A...</td>\n",
       "      <td>tableau, power bi</td>\n",
       "      <td>25</td>\n",
       "      <td>PONTARLIER</td>\n",
       "      <td>2023/08/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer        (H/F)</td>\n",
       "      <td>Selon vos expériences, votre mission sera de :...</td>\n",
       "      <td>33 - BORDEAUX</td>\n",
       "      <td>Actualisé le 07 août 2023</td>\n",
       "      <td>38H30 Travail en journée</td>\n",
       "      <td>30000.0 - 50000.0</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>3 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>Conseil en systèmes et logiciels informatiques</td>\n",
       "      <td>THELIO</td>\n",
       "      <td>20 à 49 salariés</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tableau, power bi, talend, databricks, snowfla...</td>\n",
       "      <td>33</td>\n",
       "      <td>BORDEAUX</td>\n",
       "      <td>2023/08/07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        jobs  \\\n",
       "0  ANALYSTE APPLICATIF DATA FINANCE RH (H/F)   \n",
       "1                       Ingénieur DATA (H/F)   \n",
       "2              Data Integrity Analyst  (H/F)   \n",
       "3                      Technicien Data (h/f)   \n",
       "4                 Data Engineer        (H/F)   \n",
       "\n",
       "                                         description  \\\n",
       "0  Dans le cadre d'un important projet avec un gr...   \n",
       "1  Nous recherchons : un Ingénieur DATA H/F.\\n\\nP...   \n",
       "2  ADECCO Lyon Pharma recherche un Data Integrity...   \n",
       "3  Adecco PONTARLIER, recherche pour l'un de ses ...   \n",
       "4  Selon vos expériences, votre mission sera de :...   \n",
       "\n",
       "                        loc                 datePosted  \\\n",
       "0  92 - ISSY LES MOULINEAUX  Actualisé le 07 août 2023   \n",
       "1              92 - PUTEAUX  Actualisé le 07 août 2023   \n",
       "2            69 - ST PRIEST  Actualisé le 07 août 2023   \n",
       "3           25 - PONTARLIER  Actualisé le 07 août 2023   \n",
       "4             33 - BORDEAUX  Actualisé le 07 août 2023   \n",
       "\n",
       "                  workhours             salary                  contract_type  \\\n",
       "0    35H Travail en journée  50000.0 - 60000.0   Contrat à durée indéterminée   \n",
       "1    35H Travail en journée                NaN   Contrat à durée indéterminée   \n",
       "2    35H Travail en journée             2311.0  Mission intérimaire - 12 Mois   \n",
       "3    35H Travail en journée                NaN   Contrat à durée indéterminée   \n",
       "4  38H30 Travail en journée  30000.0 - 50000.0   Contrat à durée indéterminée   \n",
       "\n",
       "         experience                      diploma  \\\n",
       "0             2 ans                          NaN   \n",
       "1             2 ans  Bac+3, Bac+4 ou équivalents   \n",
       "2  Débutant accepté                          NaN   \n",
       "3  Débutant accepté                          NaN   \n",
       "4             3 ans                          NaN   \n",
       "\n",
       "                                              skills     qualifications  \\\n",
       "0  [Adapter les outils de traitement statistique ...              Cadre   \n",
       "1  [Application web, Concevoir une application we...  Agent de maîtrise   \n",
       "2  [Adapter les outils de traitement statistique ...   Employé qualifié   \n",
       "3  [Concevoir et gérer un projet, Concevoir un lo...   Employé qualifié   \n",
       "4                                                 []              Cadre   \n",
       "\n",
       "                                            industry          company  \\\n",
       "0     Conseil en systèmes et logiciels informatiques  INFORMATIS T.S.   \n",
       "1  Conseil pour les affaires et autres conseils d...    IL CONSULTING   \n",
       "2        Activités des agences de travail temporaire    ADECCO Onsite   \n",
       "3        Activités des agences de travail temporaire           ADECCO   \n",
       "4     Conseil en systèmes et logiciels informatiques           THELIO   \n",
       "\n",
       "                                                size  \\\n",
       "0                                     6 à 9 salariés   \n",
       "1                                                NaN   \n",
       "2  0 salarié (n'ayant pas d'effectif au 31/12 mai...   \n",
       "3                                     6 à 9 salariés   \n",
       "4                                   20 à 49 salariés   \n",
       "\n",
       "                                 company_description  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  Premier réseau d'agences d'emploi en France, A...   \n",
       "3  Premier réseau d'agences d'emploi en France, A...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               tools ID_dep  \\\n",
       "0                                                NaN     92   \n",
       "1                        gitlab, kubernetes, mongodb     92   \n",
       "2                                                NaN     69   \n",
       "3                                  tableau, power bi     25   \n",
       "4  tableau, power bi, talend, databricks, snowfla...     33   \n",
       "\n",
       "                 ville        date  \n",
       "0  ISSY LES MOULINEAUX  2023/08/07  \n",
       "1              PUTEAUX  2023/08/07  \n",
       "2            ST PRIEST  2023/08/07  \n",
       "3           PONTARLIER  2023/08/07  \n",
       "4             BORDEAUX  2023/08/07  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f137f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df[['ID_dep', 'ville']] = df['loc'].str.split(' - ', expand = True)\n",
    "    df['date'] = df['datePosted'].str.replace('Actualisé le ', '').str.replace('Publié le ', '')\n",
    "    df['date'] = df['date'].apply(lambda x: dateparser.parse(x, languages=['fr']))\n",
    "    df['date'] = df['date'].dt.strftime('%Y/%m/%d')\n",
    "    \n",
    "    df[\"jobs\"] = df[\"jobs\"].str.replace(\" h/f\", \"\")\n",
    "    df[\"jobs\"] = df[\"jobs\"].str.replace(\"\\s*\\([hH]/[fF]\\)\\s*\", \" \").str.strip()\n",
    "    df[\"jobs\"] = df[\"jobs\"].str.replace(\" (H/F)\", \"\")\n",
    "    df[\"jobs\"] = df[\"jobs\"].str.replace(\" H/F\", \"\")\n",
    "    df[\"jobs\"] = df[\"jobs\"].str.replace(\" F/H\", \"\")\n",
    "    df[\"jobs\"] = df[\"jobs\"].str.replace(\" (F/H)\", \"\")\n",
    "    df[\"jobs\"] = df[\"jobs\"].str.replace(\" \\(\\)\", \"\")\n",
    "\n",
    "    \n",
    "    df = df.applymap(lambda x: ','.join(map(str, x)) if isinstance(x, list) else x)\n",
    "    df = df.drop([\"loc\", \"datePosted\"], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f0497b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m transform_data(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5761b381",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2938a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nan(df):\n",
    "    \n",
    "    nan_counts = df.isna().sum() # compte le nombre de NaN pour chaque colonne\n",
    "    total_counts = len(df) # compte le nombre total de données dans le dataframe\n",
    "    nan_percentages = (nan_counts / total_counts) * 100 # calcule le pourcentage de NaN pour chaque colonne\n",
    "    result_df = pd.concat([nan_counts, nan_percentages], axis=1) # combine les deux séries en un dataframe\n",
    "    result_df.columns = ['NaN Count', 'NaN Percentage'] # renomme les colonnes du nouveau dataframe\n",
    "    result_df = result_df.sort_values(by = ['NaN Count'], ascending = False)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62758c2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_nan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m count_nan(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_nan' is not defined"
     ]
    }
   ],
   "source": [
    "count_nan(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80413bb6",
   "metadata": {},
   "source": [
    "### Export Transform df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e70347a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_silver_to_csv(df):\n",
    "    # Obtenez la date actuelle\n",
    "    current_date = date.today().strftime(\"%d_%m_%Y\")\n",
    "\n",
    "    # Assurez-vous que le dossier de destination existe\n",
    "    folder_path = f\"../data/silver/{current_date}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Exportez le DataFrame dans un fichier CSV\n",
    "    csv_file_path = f\"{folder_path}/jobs_data.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6dea86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_silver_to_csv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d497e4",
   "metadata": {},
   "source": [
    "### Concat silver and transform df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9afc6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data(df):\n",
    "    \n",
    "    # importer le df qui contient toutes les données déjà récoltées\n",
    "    df_history = pd.read_csv(\"../data/silver/silver_data.csv\")\n",
    "    \n",
    "    # concaténer les données qui viennent d'être récoltées à df_history\n",
    "    global_df = pd.concat([df_history, df], axis=0)\n",
    "    sort_df = global_df.sort_values('date', ascending=True)\n",
    "    \n",
    "    return sort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ae92e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df = concat_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7a5935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobs</th>\n",
       "      <th>description</th>\n",
       "      <th>loc</th>\n",
       "      <th>datePosted</th>\n",
       "      <th>workhours</th>\n",
       "      <th>salary</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>experience</th>\n",
       "      <th>diploma</th>\n",
       "      <th>skills</th>\n",
       "      <th>qualifications</th>\n",
       "      <th>industry</th>\n",
       "      <th>company</th>\n",
       "      <th>size</th>\n",
       "      <th>company_description</th>\n",
       "      <th>tools</th>\n",
       "      <th>ID_dep</th>\n",
       "      <th>ville</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Data Engineer sénior (F/H) CDI (H/F)</td>\n",
       "      <td>En tant que Data Engineer chez Quantmetry, vou...</td>\n",
       "      <td>75 - PARIS 08</td>\n",
       "      <td>Actualisé le 12 juillet 2023</td>\n",
       "      <td>38H Travail en journée</td>\n",
       "      <td>40000.0 - 50000.0</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>5 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concevoir et gérer un projet,Concevoir un logi...</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>Conseil pour les affaires et autres conseils d...</td>\n",
       "      <td>QUANTMETRY</td>\n",
       "      <td>100 à 199 salariés</td>\n",
       "      <td>Pure player en Data et Intelligence Artificiel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 08</td>\n",
       "      <td>2023/07/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Data Consultant Stratégie Sénior (H/F)</td>\n",
       "      <td>Nous recrutons des personnes avec une appétenc...</td>\n",
       "      <td>75 - PARIS 08</td>\n",
       "      <td>Actualisé le 12 juillet 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>3100.0 - 5000.0</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>5 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Analyser les résultats d'un projet,Décliner la...</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>Conseil pour les affaires et autres conseils d...</td>\n",
       "      <td>QUANTMETRY</td>\n",
       "      <td>100 à 199 salariés</td>\n",
       "      <td>Pure player en Data et Intelligence Artificiel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 08</td>\n",
       "      <td>2023/07/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Data Consultant Stratégie Sénior (H/F)</td>\n",
       "      <td>Nous recrutons des personnes avec une appétenc...</td>\n",
       "      <td>75 - PARIS 08</td>\n",
       "      <td>Actualisé le 12 juillet 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>3100.0 - 5000.0</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>5 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Analyser les résultats d'un projet\", \"Déclin...</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>Conseil pour les affaires et autres conseils d...</td>\n",
       "      <td>QUANTMETRY</td>\n",
       "      <td>100 à 199 salariés</td>\n",
       "      <td>Pure player en Data et Intelligence Artificiel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 08</td>\n",
       "      <td>2023/07/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Data Engineer sénior (F/H) CDI (H/F)</td>\n",
       "      <td>En tant que Data Engineer chez Quantmetry, vou...</td>\n",
       "      <td>75 - PARIS 08</td>\n",
       "      <td>Actualisé le 12 juillet 2023</td>\n",
       "      <td>38H Travail en journée</td>\n",
       "      <td>40000.0 - 50000.0</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>5 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Concevoir et gérer un projet', \"Concevoir un...</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>Conseil pour les affaires et autres conseils d...</td>\n",
       "      <td>QUANTMETRY</td>\n",
       "      <td>100 à 199 salariés</td>\n",
       "      <td>Pure player en Data et Intelligence Artificiel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 08</td>\n",
       "      <td>2023/07/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Chef de projets Performance Durable/Energie/Da...</td>\n",
       "      <td>Intégré(e) au sein de la Direction Performance...</td>\n",
       "      <td>92 - ASNIERES SUR SEINE</td>\n",
       "      <td>Actualisé le 13 juillet 2023</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrat à durée indéterminée</td>\n",
       "      <td>3 ans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Contrôler et faire appliquer le respect de d...</td>\n",
       "      <td>Employé qualifié</td>\n",
       "      <td>Activités des sièges sociaux</td>\n",
       "      <td>NEXITY</td>\n",
       "      <td>250 à 499 salariés</td>\n",
       "      <td>Nexity est aujourd hui leader sur les différen...</td>\n",
       "      <td>tableau</td>\n",
       "      <td>92</td>\n",
       "      <td>ASNIERES SUR SEINE</td>\n",
       "      <td>2023/07/13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  jobs  \\\n",
       "139               Data Engineer sénior (F/H) CDI (H/F)   \n",
       "138             Data Consultant Stratégie Sénior (H/F)   \n",
       "138             Data Consultant Stratégie Sénior (H/F)   \n",
       "139               Data Engineer sénior (F/H) CDI (H/F)   \n",
       "133  Chef de projets Performance Durable/Energie/Da...   \n",
       "\n",
       "                                           description  \\\n",
       "139  En tant que Data Engineer chez Quantmetry, vou...   \n",
       "138  Nous recrutons des personnes avec une appétenc...   \n",
       "138  Nous recrutons des personnes avec une appétenc...   \n",
       "139  En tant que Data Engineer chez Quantmetry, vou...   \n",
       "133  Intégré(e) au sein de la Direction Performance...   \n",
       "\n",
       "                         loc                    datePosted  \\\n",
       "139            75 - PARIS 08  Actualisé le 12 juillet 2023   \n",
       "138            75 - PARIS 08  Actualisé le 12 juillet 2023   \n",
       "138            75 - PARIS 08  Actualisé le 12 juillet 2023   \n",
       "139            75 - PARIS 08  Actualisé le 12 juillet 2023   \n",
       "133  92 - ASNIERES SUR SEINE  Actualisé le 13 juillet 2023   \n",
       "\n",
       "                  workhours             salary                 contract_type  \\\n",
       "139  38H Travail en journée  40000.0 - 50000.0  Contrat à durée indéterminée   \n",
       "138  35H Travail en journée    3100.0 - 5000.0  Contrat à durée indéterminée   \n",
       "138  35H Travail en journée    3100.0 - 5000.0  Contrat à durée indéterminée   \n",
       "139  38H Travail en journée  40000.0 - 50000.0  Contrat à durée indéterminée   \n",
       "133  35H Travail en journée                NaN  Contrat à durée indéterminée   \n",
       "\n",
       "    experience diploma                                             skills  \\\n",
       "139      5 ans     NaN  Concevoir et gérer un projet,Concevoir un logi...   \n",
       "138      5 ans     NaN  Analyser les résultats d'un projet,Décliner la...   \n",
       "138      5 ans     NaN  [\"Analyser les résultats d'un projet\", \"Déclin...   \n",
       "139      5 ans     NaN  ['Concevoir et gérer un projet', \"Concevoir un...   \n",
       "133      3 ans     NaN  ['Contrôler et faire appliquer le respect de d...   \n",
       "\n",
       "       qualifications                                           industry  \\\n",
       "139             Cadre  Conseil pour les affaires et autres conseils d...   \n",
       "138             Cadre  Conseil pour les affaires et autres conseils d...   \n",
       "138             Cadre  Conseil pour les affaires et autres conseils d...   \n",
       "139             Cadre  Conseil pour les affaires et autres conseils d...   \n",
       "133  Employé qualifié                       Activités des sièges sociaux   \n",
       "\n",
       "        company                size  \\\n",
       "139  QUANTMETRY  100 à 199 salariés   \n",
       "138  QUANTMETRY  100 à 199 salariés   \n",
       "138  QUANTMETRY  100 à 199 salariés   \n",
       "139  QUANTMETRY  100 à 199 salariés   \n",
       "133      NEXITY  250 à 499 salariés   \n",
       "\n",
       "                                   company_description    tools ID_dep  \\\n",
       "139  Pure player en Data et Intelligence Artificiel...      NaN     75   \n",
       "138  Pure player en Data et Intelligence Artificiel...      NaN     75   \n",
       "138  Pure player en Data et Intelligence Artificiel...      NaN     75   \n",
       "139  Pure player en Data et Intelligence Artificiel...      NaN     75   \n",
       "133  Nexity est aujourd hui leader sur les différen...  tableau     92   \n",
       "\n",
       "                  ville        date  \n",
       "139            PARIS 08  2023/07/12  \n",
       "138            PARIS 08  2023/07/12  \n",
       "138            PARIS 08  2023/07/12  \n",
       "139            PARIS 08  2023/07/12  \n",
       "133  ASNIERES SUR SEINE  2023/07/13  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8eecb9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 19)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "986307d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobs                      0\n",
       "description               0\n",
       "loc                       0\n",
       "datePosted                0\n",
       "workhours              1606\n",
       "salary                 1578\n",
       "contract_type             0\n",
       "experience                0\n",
       "diploma                1870\n",
       "skills                    0\n",
       "qualifications          878\n",
       "industry                844\n",
       "company                 862\n",
       "size                    622\n",
       "company_description     928\n",
       "tools                   818\n",
       "ID_dep                    0\n",
       "ville                   246\n",
       "date                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a14963b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 19)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = global_df.loc[global_df.duplicated()]\n",
    "loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0d89c800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df = global_df.drop_duplicates()\n",
    "global_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8bd9e107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023/07/12'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df[\"date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "56eec68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023/08/07'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df[\"date\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1ce04",
   "metadata": {},
   "source": [
    "### Export silver df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "328b4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_silver_df(df):\n",
    "    csv_file_path = f\"../data/silver/silver_data.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2ced35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_silver_df(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
